# 模型服务自动化上线  
## 概述  
自动化上线包括四个大步骤：  
0） 初次上线，需要在10.77.136.198上创建monitor模型目录；  
1） 将新版本推送到monitor服务器；每次有新版本时执行；  
2） monitor定期检查是否有新版本，有新版本则修改在线版本库和配置文件service.conf；  
3） 各模型服务定期检查service.conf，根据内容是否更改进行升级（冷启动）。

# 第一部分  初次自动化上线相关操作
## 初次自动化上线流程 
```
graph LR
申请服务发现-->准备数据
准备数据-->monitor上建立相应模型库目录
monitor上建立相应模型库目录-->推送新的数据文件
推送新的数据文件-->修改service.conf
修改service.conf-->启动docker
启动docker-->验证docker可用
验证docker可用-->查看zk状态
```  
下面以黄色微博mblog_yellow为例介绍上线流程及注意事项，测试机为10.77.100.69
## 1.申请服务发现
### 申请服务发现
参数：  
> #zk集群，一般不用修改  
cluster_id=zk://10.39.11.60:2181,10.39.11.61:2181,10.39.11.62:2181,10.39.11.63:2181,10.39.11.64:2181  
#zk组id 
group_id=media_service  
#zk服务id, 需自定义
service_id=mblog_yellow  
注意使用时将group_id、service_id替换为相应模型的信息
```
参考命令如下：  
 curl http://i2.api.weibo.com/2/darwin/application/service_discovery/registe_service.json -d 'source=646811797&cluster_id=zk://10.39.11.60:2181,10.39.11.61:2181,10.39.11.62:2181,10.39.11.63:2181,10.39.11.64:2181&group_id=media_service&service_id=yourserviceid&mail=changjun6' 
```
## 2.在测试机上准备数据  
1. 模型的data(模型参数)和release(mblog_yellow.so)文件，具体放到测试机哪个路径，步骤四中有介绍; 
2. docker镜像;  
## 3.monitor上建立相应模型库目录 
**1.操作步骤**  
执行下面脚本：  
/data0/monitor/scripts/add_dispatch_docker.sh 

参数如下：  
type: model(根据模型选择)   
module: 版本文件夹的名字  
plugin: .so库的名字，不包含".so"
```  
cd /data0/monitor/scripts
sh add_dispatch_docker.sh model mblog_yellow mblog_yellow  
```
**2.检查**  
(1)add_dispatch_docker.sh脚本执行后，dispatchserver.sh脚本中会添加相应的模型服务信息：  
```  
cat /data1/monitor/scripts/dispatch/bin/dispatchserver.sh 
# mblog_yellow
# add by yuxiang8
mymodel="mblog_yellow"
plugin="mblog_yellow"
echo "==================begin start run $mymodel================================="`date`  >> ${logFile}
sh dispatch.sh $mymodel /data1/work/datasys/framework/service/workspace/plugin/$mymodel $plugin.so >> ${logFile}
echo "==================end run $mymodel========================================="`date`  >> ${logFile}
```
(2)检查是否存在新建的两个文件夹(非空)。 
>/data1/monitor/rsync_service_data/datamining_plugin/mblog_yellow  
>/data1/monitor/rsync_service_data/datamining_service/mblog_yellow   

(3)如果上述都没问题，说明创建成功。

## 4.推送新的数据文件  
1. 脚本地址：http://git.intra.weibo.com/datastrategy/dockerbuilder/tree/master/online/auto_deploy/
复制pic_deploy/online_pic_download_aliyun/（请勿修改）文件夹到测试机上,同时将pic_deploy/online_pic_download_aliyun/改名为/text_deploy/mblog_yellow。  
2. 将data、release文件夹放在/data0/user/changjun6/dockerbuilder/online/auto_deploy/text_deploy/mblog_yellow/online目录下。  
3. 修改/data0/user/changjun6/dockerbuilder/online/auto_deploy/text_deploy/mblog_yellow目录下的env.sh，包括线上集群机器列表、模型名称、模型端口号，env.sh内容如下:
```
monitor="10.77.136.198"  --monitor机器
members="10.77.96.239..." --线上机器列表
# user defined section
modulename=mblog_yellow    --必须与release/xxx.so同名  
moduleport=17019       --模型端口   
```
4. 以后其他模型上线，只需要在测试机上将mblog_yellow复制并将文件名改为新的模型名称，然后在该新的文件夹下修改内容即可。  
5. 功能：推送so和模型数据到monitor的datamining_plugin。    
6. 在测试机上执行以下操作：  
```
cd /data0/user/changjun6/dockerbuilder/online/auto_deploy/text_deploy/mblog_yellow  
sh rsync.sh update  
```
7. 登记模型服务信息  
为便于以后管理服务端口等信息，需要在下面文件中登记模型相应信息  
[多媒体插件端口占用及服务发现serviceid.md](http://git.intra.weibo.com/algorithm/intra/blob/master/computing_platform/model_service/deploy/多媒体插件端口占用及服务发现serviceid.md) 

8. 检查，推送数据会更新以下文件  
> /data0/monitor/rsync_service_data/datamining_plugin/mblog_yellow/lib/  
/data0/monitor/rsync_service_data/datamining_plugin/mblog_yellow/data/  
/data0/monitor/rsync_service_data/datamining_plugin/success  
注意这里是推送到datamining_plugin，datamining_service是每隔一段时间自动更新。 

## 5.修改service.conf
因为自动生成的service.conf有错误，需要用自己修改好的service.conf替换下面自动生成的service.conf文件。只需要在第一次模型上线时修改，以后模型更新无需再修改。  
> /data1/monitor/rsync_service_data/datamining_service/mblog_yellow/config_1/service.conf   
注意检查端口、模块的名称、模块参数等是否正确。
## 6.启动docker 
>在测试机10.77.100.69上执行以下操作   
```
[root@h107710069 mblog_yellow]# cd /data0/user/changjun6/dockerbuilder/online/textmining_service/mblog_yellow   
[root@h107710069 mblog_yellow]# build --no-cache=true -t "registry.intra.weibo.com/weibo_rd_algorithmplatform/mblog_yellow:v1.0"  
//dockerrun.sh usage:  [version] [docker_name] [port] [service_name]"  
[root@h107710069 mblog_yellow]# ./dockerrun.sh v1.0  mblog_yellow 17019 mblog_yellow  
```
## 7.验证docker  
```
[root@h107710069 mblog_yellow]#  docker images|grep mblog_yellow  
registry.intra.weibo.com/weibo_rd_algorithmplatform/mblog_yellow                   v1.0                       067de1d0b900        12 days ago         1.86 GB  
```
## 8.查看zk状态
>mblog_yellow [zk状态][zk状态](http://i2.api.weibo.com/darwin/application/service_discovery/get_service.json?source=2110367561&cluster_id=zk://10.39.11.60:2181,10.39.11.61:2181,10.39.11.62:2181,10.39.11.63:2181,10.39.11.64:2181&group_id=media_service&service_id=mblog_yellow&type=test)   
# 第二部分  更新模型相关操作
## 模型升级操作过程如下：
主要包括两部分  
1.在下面目录中用新的release、data新文件替换旧文件；
```
cd /data0/user/changjun6/dockerbuilder/online/auto_deploy/text_deploy/mblog_yellow
``` 
2.执行上面步骤中第四步操作，只需要执行   
```
sh rsync.sh update  
```
### 更新模型库过程介绍，以下无需操作 
1. /data0/monitor/scripts/dispatch/bincrontab.sh有下列一行,每分钟检查是否需要更新模型库。
```
# * * * * cd /data1/monitor/scripts/dispatch/bin && sh dispatchserver.sh > /dev/null 2>&1
```
2. /data0/monitor/scripts/dispatch/bin/dispatch.sh 介绍  
dispatch.sh 三个参数的含义：
> appname=$1       // 模型文件夹  
> prefixPath=$2    // 动态库的路径  
> soName=$3        // 动态库的名字  

dispatch.sh中的fUpdateVersion（）流程如下：  
如果${serviceRootPath}/$appname/status存在，则退出；  
如果${pluginRootPath}/$appname/success存在，进行更新：  
1）生成status文件；  
2）拷贝模型：$pluginRootPath/$appname/* -> $serviceRootPath/$appname/plugin/$version  
3）更改service.conf中的：moduleversion=${version}  
4）更改service.conf中的：modulepath  
sed -i -r "s/modulepath=\S*+/modulepath=${replaceprefixPath}\/${version}\/lib\/$soName/g"  
5）更改service.conf中的：moduleconfig  
sed -i -r "s/moduleconfig=\S*+/moduleconfig=${replaceprefixPath}\/${version}\/data/g"  

dispatch.sh中的fCheckVersion（）流程如下：  
1）20分钟超时，未升级完也删除status和success文件，方便下次升级；  
2）检查每个ip的版本号是否已经升级成功，未成功退出；  
3）都升级成功，删除status和success文件；  

## 模型升级  
各模型服务通过定期任务检查并升级，crontab命令如下：

```
* * * * * /bin/bash   /watch/service_polling.sh  >>/watch/log/polling-$(date+"\%Y\%m\%d").log 2>&1


# 第三部分  只进行部分自动更新（尚未完成）    
1）部分机器禁用自动更新  
方案一：rsync禁用IP  
/etc/rsyncd.conf  
hosts deny = 10.85.136.181,10.85.136.182,10.85.136.183,10.85.136.184,10.85.136.185,10.85.136.186,10.85.136.187,10.85.136.188,10.85.136.189,10.85.136.190,10.85.136.191,10.85.136.192,10.85.136.193,10.85.136.194,10.85.136.195,10.85.136.196,10.85.136.197,10.85.136.198,10.85.136.199,10.85.136.200,10.85.136.201,10.85.136.202,10.85.136.203,10.85.136.206,10.85.136.207,10.85.136.208,10.85.136.209,10.85.136.210,10.85.136.211,10.85.136.212  

启动rsync:  
rsync --daemon 或 rsync --daemon --config=/etc/rsyncd.conf  
停止rsync:（没有找到pid，不重启hosts deny没有生效，全量升级了）  
cat /tmp/rsyncd.pid | xargs kill -9 && rm -rf /tmp/rsyncd.pid   


方案二：关闭自动更新(暂停)  
/var/spool/cron/root  

// 删除crontab任务  
sed -i '/test2.sh/d' /var/spool/cron/root  
// 删除空行  
sed -i '/^$/d' /var/spool/cron/root
//
